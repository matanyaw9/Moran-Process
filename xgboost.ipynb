{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Here I will try to train an XGBOOST ML to Predict Fixation Time for Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "\n",
    "# Configuration\n",
    "batch_name = 'batch_' + 'Test_batch_name_01'\n",
    "\n",
    "ROOT = Path(os.getcwd())\n",
    "DATA_PATH = ROOT / \"simulation_data\" / batch_name / f\"graph_statistics.csv\"\n",
    "\n",
    "print(\"Setup Complete. Ready to load data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Data\n",
    "drop_raw = ['graph6_string','branching', 'depth', 'n_rods', 'rods_length', 'rod_length', 'seed', 'n_grouped']\n",
    "df = pd.read_csv(DATA_PATH).drop(columns=drop_raw, errors='ignore')\n",
    "df = df[df['r'] == 1.1]\n",
    "\n",
    "# 2. Define Features vs Target\n",
    "# We want to predict 'median_steps'\n",
    "target_col = 'mean_steps'\n",
    "\n",
    "# Columns that are ID identifiers or leakage (answers)\n",
    "drop_cols = [\n",
    "    'wl_hash', 'graph_name', 'r', 'q25_steps', 'q75_steps', 'iqr_steps',        # IDs (not features)\n",
    "    'prob_fixation',                # Different prediction task\n",
    "    'median_steps', 'mean_steps', 'std_steps', # The Answers (Leakage)\n",
    "    'category', 'graph_type', 'density'        # Strings (Drop for now to keep it simple)\n",
    "]\n",
    "drop_cols = [col for col in drop_cols if col in df.columns]\n",
    "\n",
    "# 3. Create X and y\n",
    "# We use select_dtypes to ensure we only pass numbers to the models\n",
    "X = df.drop(columns=drop_cols, errors='ignore').select_dtypes(include=[np.number])\n",
    "y = df[target_col]\n",
    "\n",
    "# 4. Handle Missing Values\n",
    "X = X.fillna(-1)\n",
    "\n",
    "print(f\"Data Loaded.\")\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "print(\"Feature list:\", list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# 1. Split Data (Once for both models)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Model A: Linear Regression Baseline ---\n",
    "print(\"\\n--- Linear Regression Results ---\")\n",
    "\n",
    "# lr = LinearRegression()\n",
    "# lr.fit(X_train, y_train)\n",
    "# lr_preds = lr.predict(X_test)\n",
    "\n",
    "# # Optional: Show which features drive the linear model\n",
    "# coef_df = pd.DataFrame({'feature': X.columns, 'coefficient': lr.coef_})\n",
    "# print(\"\\nTop 5 Features (Linear Regression):\")\n",
    "# print(coef_df.sort_values(by='coefficient', key=abs, ascending=False).head(5))\n",
    "\n",
    "\n",
    "std_lr = make_pipeline(StandardScaler(), LinearRegression())\n",
    "std_lr.fit(X_train, y_train)\n",
    "lr_preds = std_lr.predict(X_test)\n",
    "coefficients = std_lr.named_steps['linearregression'].coef_\n",
    "# Create a DataFrame for presentation\n",
    "std_coef_df = pd.DataFrame({\n",
    "    'feature': X.columns, \n",
    "    'std_coefficient': coefficients\n",
    "})\n",
    "# print(std_coef_df.sort_values(by='std_coefficient', key=abs, ascending=False).head(5))\n",
    "\n",
    "print(f\"LR R^2: {r2_score(y_test, lr_preds):.4f}\")\n",
    "print(f\"LR RMSE: {root_mean_squared_error(y_test, lr_preds):.2f}\")\n",
    " \n",
    "# 1. Get absolute values of standardized coefficients\n",
    "std_coef_df['abs_coefficient'] = std_coef_df['std_coefficient'].abs()\n",
    "\n",
    "# 2. Calculate percentage\n",
    "total_magnitude = std_coef_df['abs_coefficient'].sum()\n",
    "std_coef_df['contribution_pct'] = (std_coef_df['abs_coefficient'] / total_magnitude) * 100\n",
    "\n",
    "# 3. Sort and show\n",
    "presentation_df = std_coef_df.sort_values(by='contribution_pct', ascending=False)\n",
    "print(presentation_df[['feature', 'std_coefficient', 'contribution_pct']].head(5).to_string(float_format=lambda x: f'{x:.2f}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Predicted vs Actual for Linear Regression\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hexbin(y_test, lr_preds, gridsize=30, cmap='Blues', mincnt=1)\n",
    "plt.colorbar(label='Count')\n",
    "# plt.scatter(y_test, lr_preds, alpha=0.5, edgecolors='k', linewidth=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual mean_steps')\n",
    "plt.ylabel('Predicted mean_steps')\n",
    "plt.title('Linear Regression: Predicted vs Actual')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Model B: XGBoost ---\n",
    "print(\"\\n--- XGBoost Results ---\")\n",
    "# Check this before .fit()\n",
    "print(f\"Training on shape: {X_train.shape}\")\n",
    "mean_val = y_train.mean()\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    objective='reg:squarederror',\n",
    "    n_jobs=1,\n",
    "    random_state=42,\n",
    "    base_score=mean_val  # <--- ADD THIS LINE\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_preds = xgb_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"XGB R^2: {r2_score(y_test, xgb_preds):.4f}\")\n",
    "print(f\"XGB RMSE: {root_mean_squared_error(y_test, xgb_preds):.2f}\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hexbin(y_test, xgb_preds, gridsize=30, cmap='Reds', mincnt=1)\n",
    "plt.colorbar(label='Count')\n",
    "# plt.scatter(y_test, xgb_preds, alpha=0.5, edgecolors='k', linewidth=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual mean_steps')\n",
    "plt.ylabel('Predicted mean_steps')\n",
    "plt.title('XGBOOST: Predicted vs Actual')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.hexbin(lr_preds, xgb_preds, gridsize=30, cmap='Purples', mincnt=1)\n",
    "plt.colorbar(label='Count')\n",
    "# plt.scatter(lr_preds, xgb_preds, alpha=0.5, edgecolors='k', linewidth=0.5, c='Purple')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Full Agreement')\n",
    "plt.xlabel('Linear Regression mean_steps prediction')\n",
    "plt.ylabel('XGBOOST mean_steps prediction')\n",
    "plt.title('Linear Regression vs XGBOOST')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # --- Interpretation (SHAP) ---\n",
    "# # See what actually drives the non-linear model\n",
    "# explainer = shap.TreeExplainer(xgb_model)\n",
    "# shap_values = explainer(X_test)\n",
    "\n",
    "# plt.figure()\n",
    "# shap.summary_plot(shap_values, X_test, show=False)\n",
    "# plt.title(\"What drives Fixation Time? (XGBoost)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Interpretation (SHAP) ---\n",
    "\n",
    "# 1. Use the PermutationExplainer (The \"Black Box\" method)\n",
    "# We pass the .predict FUNCTION, not the model object. This bypasses the version conflict.\n",
    "explainer = shap.PermutationExplainer(xgb_model.predict, X_test)\n",
    "\n",
    "# 2. Calculate SHAP values\n",
    "# Note: PermutationExplainer calculates interactions, so we usually just want the main values\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Plot 1: Summary\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_test, show=False)\n",
    "plt.title(\"Feature Importance (Permutation)\")\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Dependence for the top feature\n",
    "# (The structure of shap_values might be slightly different, so we handle it safely)\n",
    "top_feature_idx = np.abs(shap_values.values).mean(0).argmax()\n",
    "top_feature_name = X_test.columns[top_feature_idx]\n",
    "\n",
    "print(f\"Plotting dependence for top feature: {top_feature_name}\")\n",
    "plt.figure()\n",
    "shap.dependence_plot(top_feature_name, shap_values.values, X_test, show=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
