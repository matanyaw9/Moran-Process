{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Here I will try to train an XGBOOST ML to Predict Fixation Time for Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import joblib\n",
    "from analysis.analysis_utils import GRAPH_PROPERTY_COLUMNS\n",
    "\n",
    "# Configuration\n",
    "BATCH_NAME = 'batch_large_test_30_02'\n",
    "\n",
    "\n",
    "ROOT = Path(os.getcwd())\n",
    "BATCH_DIR = ROOT / \"simulation_data\" / BATCH_NAME\n",
    "DATA_PATH = BATCH_DIR / f\"graph_statistics.csv\"\n",
    "\n",
    "TARGET_COLUMN = 'prob_fixation' # \"prob_fixation\" or \"mean_steps\"\n",
    "\n",
    "print(\"Setup Complete. Ready to load data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_raw = ['graph6_string','branching', 'depth', 'n_rods', 'rods_length', 'rod_length', 'seed', 'n_grouped']\n",
    "\n",
    "df = pd.read_csv(DATA_PATH).drop(columns=drop_raw, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Load Data\n",
    "df = df[df['r'] == 1.1]\n",
    "\n",
    "# 3. Create X and y\n",
    "# We use select_dtypes to ensure we only pass numbers to the models\n",
    "X = df[GRAPH_PROPERTY_COLUMNS].select_dtypes(include=[np.number])\n",
    "if \"density\" in X.columns:\n",
    "    X = X.drop(columns=[\"density\"])\n",
    "y = df[TARGET_COLUMN]\n",
    "\n",
    "# 4. Handle Missing Values\n",
    "X = X.fillna(-1)\n",
    "\n",
    "print(f\"Data Loaded.\")\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "print(\"Feature list:\", list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Split Data (Once for both models)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Model A: Linear Regression Baseline ---\n",
    "print(\"\\n--- Linear Regression Results ---\")\n",
    "\n",
    "std_lr = make_pipeline(StandardScaler(), LinearRegression())\n",
    "std_lr.fit(X_train, y_train)\n",
    "lr_preds = std_lr.predict(X_test)\n",
    "coefficients = std_lr.named_steps['linearregression'].coef_\n",
    "# Create a DataFrame for presentation\n",
    "std_coef_df = pd.DataFrame({\n",
    "    'feature': X.columns, \n",
    "    'std_coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Assuming your pipeline is named std_lr\n",
    "model_filename = BATCH_DIR / \"ml_models\" / f'{TARGET_COLUMN}_linear_regression_pipeline.joblib'\n",
    "os.makedirs(os.path.dirname(model_filename), exist_ok=True)\n",
    "joblib.dump(std_lr, model_filename)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"LR R^2: {r2_score(y_test, lr_preds):.4f}\")\n",
    "print(f\"LR RMSE: {root_mean_squared_error(y_test, lr_preds):.2f}\")\n",
    " \n",
    "# 1. Get absolute values of standardized coefficients\n",
    "std_coef_df['abs_coefficient'] = std_coef_df['std_coefficient'].abs()\n",
    "\n",
    "# 2. Calculate percentage\n",
    "total_magnitude = std_coef_df['abs_coefficient'].sum()\n",
    "std_coef_df['contribution_pct'] = (std_coef_df['abs_coefficient'] / total_magnitude) * 100\n",
    "\n",
    "# 3. Sort and show\n",
    "presentation_df = std_coef_df.sort_values(by='contribution_pct', ascending=False)\n",
    "presentation_df['feature'] = presentation_df['feature'].str.replace('_', ' ').str.title()\n",
    "print(presentation_df[['feature',  'contribution_pct', 'std_coefficient',]].head(10).to_string(float_format=lambda x: f'{x:.2f}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Predicted vs Actual for Linear Regression\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hexbin(y_test, lr_preds, gridsize=30, cmap='Blues', mincnt=1)\n",
    "plt.colorbar(label='Count')\n",
    "# plt.scatter(y_test, lr_preds, alpha=0.5, edgecolors='k', linewidth=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel(f'Actual {TARGET_COLUMN}')\n",
    "plt.ylabel(f'Predicted {TARGET_COLUMN}')\n",
    "plt.title('Linear Regression: Predicted vs Actual')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "corr, p_value = pearsonr(lr_preds, y_test)\n",
    "plt.text(0.05, 0.95, f'Correlation: {corr:.4f}\\np-value: {p_value:.2e}', \n",
    "         transform=plt.gca().transAxes, fontsize=10, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Model B: XGBoost ---\n",
    "print(\"\\n--- XGBoost Results ---\")\n",
    "# Check this before .fit()\n",
    "print(f\"Training on shape: {X_train.shape}\")\n",
    "mean_val = y_train.mean()\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    objective='reg:squarederror',\n",
    "    n_jobs=1,\n",
    "    random_state=42,\n",
    "    base_score=mean_val  # <--- ADD THIS LINE\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_preds = xgb_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Save the XGBoost model\n",
    "xgb_model_filename = BATCH_DIR / \"ml_models\" / f'{TARGET_COLUMN}_xgboost_model.joblib'\n",
    "joblib.dump(xgb_model, xgb_model_filename)\n",
    "\n",
    "print(f\"XGBoost model saved to {xgb_model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"XGB R^2: {r2_score(y_test, xgb_preds):.4f}\")\n",
    "print(f\"XGB RMSE: {root_mean_squared_error(y_test, xgb_preds):.2f}\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hexbin(y_test, xgb_preds, gridsize=30, cmap='Reds', mincnt=1)\n",
    "plt.colorbar(label='Count')\n",
    "# plt.scatter(y_test, xgb_preds, alpha=0.5, edgecolors='k', linewidth=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel(f'Actual {TARGET_COLUMN}')\n",
    "plt.ylabel(f'Predicted {TARGET_COLUMN}')\n",
    "plt.title('XGBOOST: Predicted vs Actual')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "corr, p_value = pearsonr(y_test, xgb_preds)\n",
    "plt.text(0.05, 0.95, f'Correlation: {corr:.4f}\\np-value: {p_value:.2e}', \n",
    "         transform=plt.gca().transAxes, fontsize=10, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hexbin(lr_preds, xgb_preds, gridsize=30, cmap='Purples', mincnt=1)\n",
    "plt.colorbar(label='Count')\n",
    "# plt.scatter(lr_preds, xgb_preds, alpha=0.5, edgecolors='k', linewidth=0.5, c='Purple')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Full Agreement')\n",
    "plt.xlabel(f'Linear Regression {TARGET_COLUMN} prediction')\n",
    "plt.ylabel(f'XGBOOST {TARGET_COLUMN} prediction')\n",
    "plt.title(f'Linear Regression vs XGBOOST in {TARGET_COLUMN}')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Calculate and display correlation\n",
    "corr, p_value = pearsonr(lr_preds, xgb_preds)\n",
    "plt.text(0.05, 0.95, f'Correlation: {corr:.4f}\\np-value: {p_value:.2e}', \n",
    "         transform=plt.gca().transAxes, fontsize=10, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Interpretation (SHAP) ---\n",
    "\n",
    "# 1. Use the PermutationExplainer (The \"Black Box\" method)\n",
    "# We pass the .predict FUNCTION, not the model object. This bypasses the version conflict.\n",
    "explainer = shap.PermutationExplainer(xgb_model.predict, X_test)\n",
    "\n",
    "# 2. Calculate SHAP values\n",
    "# Note: PermutationExplainer calculates interactions, so we usually just want the main values\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Plot 1: Summary\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_test, show=False)\n",
    "plt.title(\"Feature Importance (Permutation)\")\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Dependence for the top feature\n",
    "# (The structure of shap_values might be slightly different, so we handle it safely)\n",
    "top_feature_idx = np.abs(shap_values.values).mean(0).argmax()\n",
    "top_feature_name = X_test.columns[top_feature_idx]\n",
    "\n",
    "print(f\"Plotting dependence for top feature: {top_feature_name}\")\n",
    "plt.figure()\n",
    "shap.dependence_plot(top_feature_name, shap_values.values, X_test, show=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Moran Process",
   "language": "python",
   "name": "moran-process"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
