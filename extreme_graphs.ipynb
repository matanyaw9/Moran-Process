{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# This script will use Evolutionary Algorithm to produce most slow fixating graphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from population_graph import PopulationGraph\n",
    "from analysis.analysis_utils import GRAPH_PROPERTY_COLUMNS\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_random_graph(graph_zoo: list[PopulationGraph], \n",
    "                         wl_set:set, \n",
    "                         n_nodes:int, \n",
    "                         n_edges:int, \n",
    "                         name:str, \n",
    "                         seed=None):\n",
    "    \n",
    "    new_graph, new_wl = None, None\n",
    "    while(new_wl is None or new_wl in wl_set):\n",
    "        new_graph = PopulationGraph.random_connected_graph(n_nodes, n_edges, name=name, seed=seed)\n",
    "        new_wl = new_graph.wl_hash\n",
    "    graph_zoo.append(new_graph)\n",
    "    wl_set.add(new_wl)\n",
    "    return wl_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Initial Random Graph Population\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "N_INITIAL_GRAPH_POPULATION = 10\n",
    "NUMBER_OF_CHILDREN = 10\n",
    "GENERATIONS = 100\n",
    "N_NODES = 31\n",
    "N_EDGES = 34\n",
    "\n",
    "random_graph_zoo:list[PopulationGraph] = []\n",
    "wl_set = set()\n",
    "\n",
    "for i in range(N_INITIAL_GRAPH_POPULATION):\n",
    "    # add_new_random_graph(graph_zoo, wl_set, N_NODES, N_EDGES, name=f\"random-{i}\", seed=int(rng.integers(0, 2**32)))\n",
    "    new_graph, new_wl = None, None\n",
    "    while(new_wl is None or new_wl in wl_set):\n",
    "        new_graph = PopulationGraph.random_connected_graph(N_NODES, N_EDGES, name=f\"random-{i}\", seed=None)\n",
    "        new_wl = new_graph.wl_hash\n",
    "    random_graph_zoo.append(new_graph)\n",
    "    wl_set.add(new_wl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evolutionary_search_multi_model(\n",
    "    initial_population: list,\n",
    "    model, \n",
    "    model_name, \n",
    "    secondary_models: dict = None,\n",
    "    generations: int = 50, \n",
    "    pop_size: int = 10,\n",
    "    n_children: int = 50, \n",
    "    objective: str = \"maximize\",\n",
    "    rng: np.random.Generator = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs a (mu + lambda) evolutionary strategy.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(42)\n",
    "\n",
    "    # 1. Initialize State\n",
    "    current_pop = initial_population.copy()\n",
    "    wl_set = set([g.wl_hash for g in current_pop])\n",
    "    prop_cache = {} \n",
    "    \n",
    "    # Initialize history dynamically\n",
    "    history = {'best_fitness': [], 'avg_fitness': []}\n",
    "    if secondary_models:\n",
    "        for key in secondary_models.keys():\n",
    "            history[key] = [] # Create an empty list for each secondary model\n",
    "\n",
    "    print(f\"Starting Evolution: {generations} generations, optimization: {objective} {model_name}\")\n",
    "\n",
    "    for gen in tqdm(range(generations), desc=\"Evolving\"):\n",
    "        \n",
    "        # --- A. REPRODUCTION ---\n",
    "        children = []\n",
    "        max_attempts = 10\n",
    "        \n",
    "        for parent in current_pop:\n",
    "            for i in range(n_children):\n",
    "                attempts = 0\n",
    "                while attempts < max_attempts: \n",
    "                    seed = rng.integers(0, 2**32)\n",
    "                    new_name = f'{parent.name.split(\"_\")[0]}_gen_{gen}' \n",
    "                    \n",
    "                    child = parent.mutate_graph(seed=seed, name=new_name)\n",
    "                    \n",
    "                    if child.wl_hash not in wl_set:\n",
    "                        children.append(child)\n",
    "                        wl_set.add(child.wl_hash)\n",
    "                        break\n",
    "                    attempts += 1\n",
    "\n",
    "        # --- B. EVALUATION ---\n",
    "        candidates = current_pop + children\n",
    "        \n",
    "        for g in candidates:\n",
    "            if g.wl_hash not in prop_cache:\n",
    "                prop_cache[g.wl_hash] = g.calculate_graph_properties()\n",
    "\n",
    "        all_props = [prop_cache[g.wl_hash] for g in candidates]\n",
    "        X = pd.DataFrame(all_props)\n",
    "        X = X[GRAPH_PROPERTY_COLUMNS].select_dtypes(include=[np.number])\n",
    "        if \"density\" in X.columns:\n",
    "            X = X.drop(columns=[\"density\"])\n",
    "            \n",
    "        fitness_scores = model.predict(X)\n",
    "        \n",
    "        # --- C. SELECTION & SORTING ---\n",
    "        if objective == \"maximize\":\n",
    "            sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        else:\n",
    "            sorted_indices = np.argsort(fitness_scores)\n",
    "            \n",
    "        top_indices = sorted_indices[:pop_size]\n",
    "        current_pop = [candidates[i] for i in top_indices]\n",
    "        \n",
    "        # --- D. SECONDARY TRACKING & LOGGING ---\n",
    "        if secondary_models: \n",
    "            X_survivors = X.iloc[top_indices]\n",
    "            # Fixed the .items() call here\n",
    "            for key, val in secondary_models.items():\n",
    "                history[key].append(np.mean(val.predict(X_survivors)))\n",
    "        \n",
    "        # Log primary fitness metrics\n",
    "        # history['best_fitness'].append(fitness_scores[top_indices[0]])\n",
    "        history[model_name].append(np.mean(fitness_scores[top_indices]))\n",
    "\n",
    "    return current_pop, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evolutionary_search(\n",
    "    initial_population: list,\n",
    "    model, \n",
    "    secondary_model = None,\n",
    "    generations: int = 50, \n",
    "    pop_size: int = 10,\n",
    "    n_children: int = 50,  # Generate more children than parents to explore more\n",
    "    objective: str = \"maximize\", # 'maximize' for slow fixation, 'minimize' for fast\n",
    "    rng: np.random.Generator = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs a (mu + lambda) evolutionary strategy.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(42)\n",
    "\n",
    "    # 1. Initialize State\n",
    "    current_pop = initial_population.copy()\n",
    "    wl_set = set([g.wl_hash for g in current_pop])\n",
    "    \n",
    "    # Cache to avoid re-calculating properties for survivors\n",
    "    prop_cache = {} \n",
    "    \n",
    "    # History for plotting\n",
    "    history = {'best_fitness': [], 'avg_fitness': [], 'avg_fitness_secondary': []}\n",
    "\n",
    "    print(f\"Starting Evolution: {generations} generations, optimization: {objective}\")\n",
    "\n",
    "    for gen in tqdm(range(generations), desc=\"Evolving\"):\n",
    "        \n",
    "        # --- A. REPRODUCTION ---\n",
    "        children = []\n",
    "        max_attempts = 10\n",
    "        \n",
    "        for parent in current_pop:\n",
    "            for i in range(n_children):\n",
    "                attempts = 0\n",
    "                while attempts < max_attempts: \n",
    "                    seed = rng.integers(0, 2**32)\n",
    "                    parent_name = parent.name\n",
    "                    new_name = f'{parent_name.split(\"_\")[0]}_gen_{gen}' \n",
    "                    \n",
    "                    child = parent.mutate_graph(seed=seed, name=new_name)\n",
    "                    \n",
    "                    # Verify uniqueness\n",
    "                    if child.wl_hash not in wl_set:\n",
    "                        children.append(child)\n",
    "                        wl_set.add(child.wl_hash)\n",
    "                        break\n",
    "                    attempts += 1\n",
    "\n",
    "        # --- B. EVALUATION ---\n",
    "        candidates = current_pop + children\n",
    "        \n",
    "        # Calculate properties ONLY for those not in cache\n",
    "        for g in candidates:\n",
    "            if g.wl_hash not in prop_cache:\n",
    "                prop_cache[g.wl_hash] = g.calculate_graph_properties()\n",
    "\n",
    "        # Construct DataFrame for Prediction\n",
    "        all_props = [prop_cache[g.wl_hash] for g in candidates]\n",
    "        X = pd.DataFrame(all_props)\n",
    "        \n",
    "        # Ensure columns match training data exactly\n",
    "        X = X[GRAPH_PROPERTY_COLUMNS].select_dtypes(include=[np.number])\n",
    "        if \"density\" in X.columns:\n",
    "            X = X.drop(columns=[\"density\"])\n",
    "            \n",
    "        # Predict Fitness (Fixation Time)\n",
    "        fitness_scores = model.predict(X)\n",
    "        \n",
    "        # --- C. SELECTION & SORTING ---\n",
    "        \n",
    "        # 1. Get sorted indices based on the objective\n",
    "        if objective == \"maximize\":\n",
    "            # Descending order (Best = Slowest fixation)\n",
    "            sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        else:\n",
    "            # Ascending order (Best = Fastest fixation)\n",
    "            sorted_indices = np.argsort(fitness_scores)\n",
    "            \n",
    "        # 2. Keep only the top 'pop_size' indices\n",
    "        top_indices = sorted_indices[:pop_size]\n",
    "        \n",
    "        # 3. Update the current population for the next generation!\n",
    "        current_pop = [candidates[i] for i in top_indices]\n",
    "        \n",
    "        # --- D. SECONDARY TRACKING & LOGGING ---\n",
    "        \n",
    "        if secondary_model: \n",
    "            # Slice X using ONLY the top indices. No need to sort the whole dataframe.\n",
    "            X_survivors = X.iloc[top_indices]\n",
    "            \n",
    "            # Predict and average the secondary score for survivors\n",
    "            secondary_fitness_scores_avg = np.mean(secondary_model.predict(X_survivors))\n",
    "            history['avg_fitness_secondary'].append(secondary_fitness_scores_avg)\n",
    "        \n",
    "        # Log primary fitness metrics\n",
    "        best_score = fitness_scores[top_indices[0]]\n",
    "        avg_score = np.mean(fitness_scores[top_indices])\n",
    "        \n",
    "        history['best_fitness'].append(best_score)\n",
    "        history['avg_fitness'].append(avg_score)\n",
    "\n",
    "    return current_pop, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_evolution_results(history, model_name, secondary_model_name, final_pop):\n",
    "    \"\"\"\n",
    "    Analyzes and visualizes the results of an evolutionary search.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    history : dict\n",
    "        Dictionary containing evolution history with keys:\n",
    "        - 'best_fitness': list of best fitness scores per generation\n",
    "        - 'avg_fitness': list of average fitness scores per generation\n",
    "        - 'avg_fitness_secondary': list of secondary fitness scores per generation (optional)\n",
    "    model_name : str\n",
    "        Name of the primary model used for optimization\n",
    "    secondary_model_name : str\n",
    "        Name of the secondary model for tracking\n",
    "    final_pop : list\n",
    "        List of PopulationGraph objects representing the final population\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    champion : PopulationGraph\n",
    "        The top-ranked graph from the final population\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the main figure and axis\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # --- PRIMARY AXIS (ax1) ---\n",
    "    color_best = '#1f77b4'  # Standard Matplotlib blue\n",
    "    color_avg = '#45b6fe'   # Lighter blue for average\n",
    "\n",
    "    line1 = ax1.plot(history['best_fitness'], label=f\"Best: {model_name}\", color=color_best, linewidth=2)\n",
    "    line2 = ax1.plot(history['avg_fitness'], label=f\"Avg: {model_name}\", color=color_avg, linestyle=\"--\", linewidth=2)\n",
    "\n",
    "    ax1.set_xlabel(\"Generation\", fontweight='bold')\n",
    "\n",
    "    # Smart labeling for primary axis\n",
    "    if \"Probability\" in model_name:\n",
    "        ax1.set_ylabel(model_name, color=color_best, fontweight='bold')\n",
    "        ax1.set_ylim(-0.05, 1.05) # Fix bounds for probability\n",
    "    else:\n",
    "        ax1.set_ylabel(f\"{model_name} (Steps)\", color=color_best, fontweight='bold')\n",
    "\n",
    "    ax1.tick_params(axis='y', labelcolor=color_best)\n",
    "    ax1.grid(True, linestyle=':', alpha=0.7)\n",
    "\n",
    "    # Combine lines for a unified legend later\n",
    "    lines = line1 + line2\n",
    "\n",
    "    # --- SECONDARY AXIS (ax2) ---\n",
    "    if history['avg_fitness_secondary']:\n",
    "        ax2 = ax1.twinx()  # Instantiate a second axes that shares the same x-axis\n",
    "        color_sec = '#d62728'  # Standard Matplotlib red\n",
    "        \n",
    "        line3 = ax2.plot(history['avg_fitness_secondary'], label=f\"Avg Sec: {secondary_model_name}\", \n",
    "                         color=color_sec, linestyle=\"-.\", linewidth=2)\n",
    "        \n",
    "        # Smart labeling for secondary axis\n",
    "        if \"Probability\" in secondary_model_name:\n",
    "            ax2.set_ylabel(secondary_model_name, color=color_sec, fontweight='bold')\n",
    "            ax2.set_ylim(-0.05, 1.05)\n",
    "        else:\n",
    "            ax2.set_ylabel(f\"{secondary_model_name} (Steps)\", color=color_sec, fontweight='bold')\n",
    "            \n",
    "        ax2.tick_params(axis='y', labelcolor=color_sec)\n",
    "        \n",
    "        # Append to our lines list for the unified legend\n",
    "        lines += line3\n",
    "\n",
    "    # --- FINAL FORMATTING ---\n",
    "    # Extract labels from the combined lines\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax1.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=True, ncol=3)\n",
    "\n",
    "    plt.title(f\"Evolution of Respiratory Topologies\\nOptimizing: {model_name}\", fontsize=14, pad=15)\n",
    "    fig.tight_layout() # Ensures the legend and labels don't get cut off\n",
    "    plt.show()\n",
    "\n",
    "    # --- VIEW THE CHAMPION ---\n",
    "    champion = final_pop[0]\n",
    "    print(f\"Predicted Primary Fitness: {history['best_fitness'][-1]:.4f}\")\n",
    "    \n",
    "    return champion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multi_model_history(history, main_model_name, secondary_model_names, objective):\n",
    "    if isinstance(secondary_model_names, str):\n",
    "        secondary_model_names = [secondary_model_names]\n",
    "        \n",
    "    fig, ax1 = plt.subplots(figsize=(12, 7))\n",
    "    \n",
    "    # --- STYLING RULES ---\n",
    "    # Color = Algorithm Type\n",
    "    # Pattern = Metric Type\n",
    "    def get_style(model_name):\n",
    "        # Determine Color\n",
    "        if \"LR\" in model_name:\n",
    "            color = '#1f77b4' # Blue\n",
    "        elif \"XGBOOST\" in model_name:\n",
    "            color = '#d62728' # Red\n",
    "        else:\n",
    "            color = '#2ca02c' # Green (Fallback)\n",
    "            \n",
    "        # Determine Pattern\n",
    "        if \"Probability\" in model_name:\n",
    "            linestyle = \"--\" # Dashed line for Probability\n",
    "        else:\n",
    "            linestyle = \"-\"  # Solid line for Time\n",
    "            \n",
    "        return color, linestyle\n",
    "    # ---------------------\n",
    "    \n",
    "    # 1. Determine the metric for the primary (Left) axis\n",
    "    main_is_prob = \"Probability\" in main_model_name\n",
    "    \n",
    "    # 2. Setup Left Axis Labels\n",
    "    ax1.set_xlabel(\"Generation\", fontweight='bold')\n",
    "    if main_is_prob:\n",
    "        ax1.set_ylabel(\"Fixation Probability\", fontweight='bold', color='black')\n",
    "    else:\n",
    "        ax1.set_ylabel(\"Fixation Time (Steps)\", fontweight='bold', color='black')\n",
    "    \n",
    "    lines = []\n",
    "    \n",
    "    # Plot Main Model Line (Average Only)\n",
    "    c_main, ls_main = get_style(main_model_name)\n",
    "    l_main = ax1.plot(history[main_model_name], label=f\"Avg: {main_model_name} (Main)\", \n",
    "                      color=c_main, linestyle=ls_main, linewidth=3)\n",
    "    lines += l_main\n",
    "    \n",
    "    # 3. Setup Right Axis Labels\n",
    "    ax2 = ax1.twinx()\n",
    "    if not main_is_prob:  \n",
    "        ax2.set_ylabel(\"Fixation Probability\", fontweight='bold', color='black')\n",
    "    else:                 \n",
    "        ax2.set_ylabel(\"Fixation Time (Steps)\", fontweight='bold', color='black')\n",
    "        \n",
    "    # 4. Plot Secondary Models\n",
    "    for sec_name in secondary_model_names:\n",
    "        sec_is_prob = \"Probability\" in sec_name\n",
    "        \n",
    "        # Route to the correct axis based on metric\n",
    "        target_ax = ax1 if (sec_is_prob == main_is_prob) else ax2\n",
    "        \n",
    "        c_sec, ls_sec = get_style(sec_name)\n",
    "        l_sec = target_ax.plot(history[sec_name], label=f\"Avg: {sec_name}\", \n",
    "                               color=c_sec, linestyle=ls_sec, linewidth=2.5)\n",
    "        lines += l_sec\n",
    "\n",
    "    # 5. Set Limits (Ensuring Y-axes strictly start at 0)\n",
    "    if main_is_prob:\n",
    "        ax1.set_ylim(0, 1.05)\n",
    "        ax2.set_ylim(bottom=0)\n",
    "    else:\n",
    "        ax1.set_ylim(bottom=0)\n",
    "        ax2.set_ylim(0, 1.05)\n",
    "\n",
    "    # 6. Create Unified Legend\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax1.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, -0.15), \n",
    "               fancybox=True, shadow=True, ncol=2)\n",
    "    \n",
    "    # Final Formatting\n",
    "    ax1.grid(True, linestyle=':', alpha=0.7)\n",
    "    plt.title(f\"Evolution of Topologies\\nOptimizing: {objective.title()} {main_model_name}\", fontsize=14, pad=15)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TIME_LR_MODEL = \"LR Fixation Time\"\n",
    "TIME_XGBOOST_MODEL = \"XGBOOST Fixation Time\"\n",
    "PROB_LR_MODEL = \"LR Fixation Probability\"\n",
    "PROB_XGBOOST_MODEL = \"XGBOOST Fixation Probability\"\n",
    "\n",
    "models = {\n",
    "    TIME_LR_MODEL: joblib.load('ml_models/mean_steps_linear_regression_pipeline.joblib'),\n",
    "    TIME_XGBOOST_MODEL: joblib.load('ml_models/mean_steps_xgboost_model.joblib'),\n",
    "    PROB_LR_MODEL: joblib.load('ml_models/prob_fixation_linear_regression_pipeline.joblib'),\n",
    "    PROB_XGBOOST_MODEL: joblib.load('ml_models/prob_fixation_xgboost_model.joblib'),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Evolutionary Algorithm! \n",
    "for model_name in models.keys():\n",
    "    objective = \"maximize\"        # can be 'maximize' or 'minimize'\n",
    "    secondary_models = {\n",
    "        k: v \n",
    "        for k, v in models.items() \n",
    "        if k != model_name\n",
    "    }\n",
    "    # 1. Configuration\n",
    "    params = {\n",
    "        \"initial_population\": random_graph_zoo, # Start with your random zoo\n",
    "        \"model\": models[model_name],                     # Your trained Linear Regression\n",
    "        \"secondary_models\": secondary_models,\n",
    "        \"generations\": GENERATIONS,               # How long to run\n",
    "        \"pop_size\": N_INITIAL_GRAPH_POPULATION,                  # Keep top 10 elite graphs\n",
    "        \"n_children\": NUMBER_OF_CHILDREN,                # Generate 30 new mutatesd graphs per graph in the population\n",
    "        \"objective\": objective,       \n",
    "        \"rng\": rng\n",
    "    }\n",
    "    # 2. Run\n",
    "    final_pop_1, history = run_evolutionary_search_multi_model(**params)\n",
    "\n",
    "    plot_multi_model_history(history, main_model_name=model_name, secondary_model_names=list(secondary_models.keys()), objective=objective)\n",
    "    winner_graph_zoo_file = Path('graph_zoos') / (f'extreme_{objective}_{model_name.replace(\" \", \"_\")}.joblib')\n",
    "    winner_graph_zoo_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    joblib.dump(final_pop_1, winner_graph_zoo_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Run the Evolutionary Algorithm! \n",
    "# model_name = TIME_LR_MODEL\n",
    "# secondary_model_name = TIME_XGBOOST_MODEL\n",
    "# objective = \"maximize\",         # can be 'maximize' or 'minimize'\n",
    "\n",
    "# # 1. Configuration\n",
    "# params = {\n",
    "#     \"initial_population\": random_graph_zoo, # Start with your random zoo\n",
    "#     \"model\": models[model_name],                     # Your trained Linear Regression\n",
    "#     \"secondary_model\": models[secondary_model_name],\n",
    "#     \"generations\": GENERATIONS,               # How long to run\n",
    "#     \"pop_size\": N_INITIAL_GRAPH_POPULATION,                  # Keep top 10 elite graphs\n",
    "#     \"n_children\": NUMBER_OF_CHILDREN,                # Generate 30 new mutatesd graphs per graph in the population\n",
    "#     \"objective\": \"maximize\",       \n",
    "#     \"rng\": rng\n",
    "# }\n",
    "# # 2. Run\n",
    "# final_pop_1, history = run_evolutionary_search(**params)\n",
    "# champion = analyze_evolution_results(history, model_name, secondary_model_name, final_pop_1)\n",
    "# winner_graph_zoo_file = Path('graph_zoos') / ('extreme_' + model_name.replace(\" \", \"_\") + '.joblib')\n",
    "# winner_graph_zoo_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "# joblib.dump(final_pop_1, winner_graph_zoo_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph in random_graph_zoo:\n",
    "    graph.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph in final_pop_1:\n",
    "    graph.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = TIME_XGBOOST_MODEL\n",
    "secondary_model_name = PROB_XGBOOST_MODEL\n",
    "\n",
    "# 1. Configuration\n",
    "params = {\n",
    "    \"initial_population\": final_pop_1, # Start with your random zoo\n",
    "    \"model\": joblib.load(models[model_name]),                     # Your trained Linear Regression\n",
    "    \"secondary_model\": joblib.load(models[secondary_model_name]),\n",
    "    \"generations\": GENERATIONS,               # How long to run\n",
    "    \"pop_size\": N_INITIAL_GRAPH_POPULATION,                  # Keep top 10 elite graphs\n",
    "    \"n_children\": NUMBER_OF_CHILDREN,                # Generate 30 new mutatesd graphs per graph in the population\n",
    "    \"objective\": \"minimize\",         # can be 'maximize' or 'minimize'\n",
    "    \"rng\": rng\n",
    "}\n",
    "# 2. Run\n",
    "final_pop_2, history_2 = run_evolutionary_search(**params)\n",
    "analyze_evolution_results(history_2, model_name, secondary_model_name, final_pop_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph in final_pop_2:\n",
    "    graph.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
