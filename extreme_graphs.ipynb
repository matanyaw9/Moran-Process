{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# This script will use Evolutionary Algorithm to produce most slow fixating graphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from population_graph import PopulationGraph\n",
    "from analysis.analysis_utils import GRAPH_PROPERTY_COLUMNS\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "INITIAL_GRAPH_POPULATION = 10\n",
    "NUMBER_OF_CHILDREN = 10\n",
    "GENERATIONS = 100\n",
    "N_NODES = 31\n",
    "N_EDGES = 34\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_random_graph(graph_zoo: list[PopulationGraph], \n",
    "                         wl_set:set, \n",
    "                         n_nodes:int, \n",
    "                         n_edges:int, \n",
    "                         name:str, \n",
    "                         seed=None):\n",
    "    \n",
    "    new_graph, new_wl = None, None\n",
    "    while(new_wl is None or new_wl in wl_set):\n",
    "        new_graph = PopulationGraph.random_connected_graph(n_nodes, n_edges, name=name, seed=seed)\n",
    "        new_wl = new_graph.wl_hash\n",
    "    graph_zoo.append(new_graph)\n",
    "    wl_set.add(new_wl)\n",
    "    return wl_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some random graphs\n",
    "\n",
    "graph_zoo:list[PopulationGraph] = []\n",
    "wl_set = set()\n",
    "\n",
    "for i in range(INITIAL_GRAPH_POPULATION):\n",
    "    # add_new_random_graph(graph_zoo, wl_set, N_NODES, N_EDGES, name=f\"random-{i}\", seed=int(rng.integers(0, 2**32)))\n",
    "    new_graph, new_wl = None, None\n",
    "    while(new_wl is None or new_wl in wl_set):\n",
    "        new_graph = PopulationGraph.random_connected_graph(N_NODES, N_EDGES, name=f\"random-{i}\", seed=None)\n",
    "        new_wl = new_graph.wl_hash\n",
    "    graph_zoo.append(new_graph)\n",
    "    wl_set.add(new_wl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def run_evolutionary_search(\n",
    "#     initial_population: list[PopulationGraph],\n",
    "#     model, \n",
    "#     generations: int = 50, \n",
    "#     pop_size: int = 10,\n",
    "#     n_children: int = 50,  # Generate more children than parents to explore more\n",
    "#     objective: str = \"maximize\", # 'maximize' for slow fixation, 'minimize' for fast\n",
    "#     rng: np.random.Generator = None\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Runs a (mu + lambda) evolutionary strategy.\n",
    "#     \"\"\"\n",
    "#     if rng is None:\n",
    "#         rng = np.random.default_rng(42)\n",
    "\n",
    "#     # 1. Initialize State\n",
    "#     current_pop = initial_population.copy()\n",
    "#     wl_set = set([g.wl_hash for g in current_pop])\n",
    "    \n",
    "#     # We maintain a cache of properties to avoid re-calculating for survivors\n",
    "#     # Key: wl_hash, Value: dict of properties\n",
    "#     prop_cache = {} \n",
    "    \n",
    "#     # History for plotting\n",
    "#     history = {'best_fitness': [], 'avg_fitness': []}\n",
    "\n",
    "#     print(f\"Starting Evolution: {generations} generations, optimization: {objective}\")\n",
    "\n",
    "#     for gen in tqdm(range(generations), desc=\"Evolving\"):\n",
    "        \n",
    "#         # --- A. REPRODUCTION ---\n",
    "#         # Generate children from current population\n",
    "#         children = []\n",
    "#         # We try to generate n_children, ensuring they are unique\n",
    "        \n",
    "#         max_attempts = 10\n",
    "        \n",
    "#         for parent in current_pop:\n",
    "#             for i in range(n_children):\n",
    "#                 attempts = 0\n",
    "#                 while attempts < max_attempts: \n",
    "#                     seed = rng.integers(0, 2**32)\n",
    "#                     parent_name = parent.name\n",
    "#                     new_name = f'{parent_name.split(\"_\")[0]}_gen_{gen}' \n",
    "#                     # Use your efficiently defined mutate function here\n",
    "#                     child = parent.mutate_graph(seed=seed, name=new_name)\n",
    "                    \n",
    "#                     # Verify uniqueness\n",
    "#                     if child.wl_hash not in wl_set:\n",
    "#                         children.append(child)\n",
    "#                         wl_set.add(child.wl_hash)\n",
    "#                         break\n",
    "#                     attempts += 1\n",
    "\n",
    "#         # --- B. EVALUATION ---\n",
    "#         # Pool everyone together\n",
    "#         candidates = current_pop + children\n",
    "        \n",
    "#         # Calculate properties ONLY for those not in cache\n",
    "#         new_props_list = []\n",
    "#         new_graphs_to_process = []\n",
    "        \n",
    "#         for g in candidates:\n",
    "#             if g.wl_hash not in prop_cache:\n",
    "#                 new_graphs_to_process.append(g)\n",
    "\n",
    "#         # Batch calculation for new graphs\n",
    "#         if new_graphs_to_process:\n",
    "#             for g in new_graphs_to_process:\n",
    "#                 # Assuming calculate_graph_properties returns a dict\n",
    "#                 props = g.calculate_graph_properties()\n",
    "#                 prop_cache[g.wl_hash] = props\n",
    "\n",
    "#         # Construct DataFrame for Prediction\n",
    "#         # We assume GRAPH_PROPERTY_COLUMNS is available globally or passed in\n",
    "#         all_props = [prop_cache[g.wl_hash] for g in candidates]\n",
    "        \n",
    "#         X = pd.DataFrame(all_props)\n",
    "#         # Ensure columns match training data exactly\n",
    "#         X = X[GRAPH_PROPERTY_COLUMNS].select_dtypes(include=[np.number])\n",
    "#         if \"density\" in X.columns:\n",
    "#             X = X.drop(columns=[\"density\"])\n",
    "            \n",
    "#         # Predict Fitness (Fixation Time)\n",
    "#         fitness_scores = model.predict(X)\n",
    "        \n",
    "#         # Attach scores to graph objects for sorting (or zip them)\n",
    "#         scored_candidates = list(zip(candidates, fitness_scores))\n",
    "\n",
    "#         # --- C. SELECTION ---\n",
    "#         # Sort based on objective\n",
    "#         if objective == \"maximize\":\n",
    "#             # Descending order (Best = Slowest fixation)\n",
    "#             scored_candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "#         else:\n",
    "#             # Ascending order (Best = Fastest fixation)\n",
    "#             scored_candidates.sort(key=lambda x: x[1], reverse=False)\n",
    "\n",
    "#         # Keep the top 'pop_size'\n",
    "#         survivors = scored_candidates[:pop_size]\n",
    "#         current_pop = [g for g, score in survivors]\n",
    "        \n",
    "#         # Logging\n",
    "#         best_score = survivors[0][1]\n",
    "#         avg_score = np.mean([s[1] for s in survivors])\n",
    "#         history['best_fitness'].append(best_score)\n",
    "#         history['avg_fitness'].append(avg_score)\n",
    "        \n",
    "#         # Optional: Prune wl_set to save memory? \n",
    "#         # Actually, keep it to ensure we never revisit bad ancestors.\n",
    "\n",
    "#     return current_pop, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evolutionary_search(\n",
    "    initial_population: list,\n",
    "    model, \n",
    "    secondary_model = None,\n",
    "    generations: int = 50, \n",
    "    pop_size: int = 10,\n",
    "    n_children: int = 50,  # Generate more children than parents to explore more\n",
    "    objective: str = \"maximize\", # 'maximize' for slow fixation, 'minimize' for fast\n",
    "    rng: np.random.Generator = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs a (mu + lambda) evolutionary strategy.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(42)\n",
    "\n",
    "    # 1. Initialize State\n",
    "    current_pop = initial_population.copy()\n",
    "    wl_set = set([g.wl_hash for g in current_pop])\n",
    "    \n",
    "    # Cache to avoid re-calculating properties for survivors\n",
    "    prop_cache = {} \n",
    "    \n",
    "    # History for plotting\n",
    "    history = {'best_fitness': [], 'avg_fitness': [], 'avg_fitness_secondary': []}\n",
    "\n",
    "    print(f\"Starting Evolution: {generations} generations, optimization: {objective}\")\n",
    "\n",
    "    for gen in tqdm(range(generations), desc=\"Evolving\"):\n",
    "        \n",
    "        # --- A. REPRODUCTION ---\n",
    "        children = []\n",
    "        max_attempts = 10\n",
    "        \n",
    "        for parent in current_pop:\n",
    "            for i in range(n_children):\n",
    "                attempts = 0\n",
    "                while attempts < max_attempts: \n",
    "                    seed = rng.integers(0, 2**32)\n",
    "                    parent_name = parent.name\n",
    "                    new_name = f'{parent_name.split(\"_\")[0]}_gen_{gen}' \n",
    "                    \n",
    "                    child = parent.mutate_graph(seed=seed, name=new_name)\n",
    "                    \n",
    "                    # Verify uniqueness\n",
    "                    if child.wl_hash not in wl_set:\n",
    "                        children.append(child)\n",
    "                        wl_set.add(child.wl_hash)\n",
    "                        break\n",
    "                    attempts += 1\n",
    "\n",
    "        # --- B. EVALUATION ---\n",
    "        candidates = current_pop + children\n",
    "        \n",
    "        # Calculate properties ONLY for those not in cache\n",
    "        for g in candidates:\n",
    "            if g.wl_hash not in prop_cache:\n",
    "                prop_cache[g.wl_hash] = g.calculate_graph_properties()\n",
    "\n",
    "        # Construct DataFrame for Prediction\n",
    "        all_props = [prop_cache[g.wl_hash] for g in candidates]\n",
    "        X = pd.DataFrame(all_props)\n",
    "        \n",
    "        # Ensure columns match training data exactly\n",
    "        X = X[GRAPH_PROPERTY_COLUMNS].select_dtypes(include=[np.number])\n",
    "        if \"density\" in X.columns:\n",
    "            X = X.drop(columns=[\"density\"])\n",
    "            \n",
    "        # Predict Fitness (Fixation Time)\n",
    "        fitness_scores = model.predict(X)\n",
    "        \n",
    "        # --- C. SELECTION & SORTING ---\n",
    "        \n",
    "        # 1. Get sorted indices based on the objective\n",
    "        if objective == \"maximize\":\n",
    "            # Descending order (Best = Slowest fixation)\n",
    "            sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "        else:\n",
    "            # Ascending order (Best = Fastest fixation)\n",
    "            sorted_indices = np.argsort(fitness_scores)\n",
    "            \n",
    "        # 2. Keep only the top 'pop_size' indices\n",
    "        top_indices = sorted_indices[:pop_size]\n",
    "        \n",
    "        # 3. Update the current population for the next generation!\n",
    "        current_pop = [candidates[i] for i in top_indices]\n",
    "        \n",
    "        # --- D. SECONDARY TRACKING & LOGGING ---\n",
    "        \n",
    "        if secondary_model: \n",
    "            # Slice X using ONLY the top indices. No need to sort the whole dataframe.\n",
    "            X_survivors = X.iloc[top_indices]\n",
    "            \n",
    "            # Predict and average the secondary score for survivors\n",
    "            secondary_fitness_scores_avg = np.mean(secondary_model.predict(X_survivors))\n",
    "            history['avg_fitness_secondary'].append(secondary_fitness_scores_avg)\n",
    "        \n",
    "        # Log primary fitness metrics\n",
    "        best_score = fitness_scores[top_indices[0]]\n",
    "        avg_score = np.mean(fitness_scores[top_indices])\n",
    "        \n",
    "        history['best_fitness'].append(best_score)\n",
    "        history['avg_fitness'].append(avg_score)\n",
    "\n",
    "    return current_pop, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"accelerator_graphs\"\n",
    "CATEGORY = \"Accelerator\"\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression on Fixation Time\": 'ml_models/mean_steps_linear_regression_pipeline.joblib',\n",
    "    \"XGBOOST on Fixation Time\": 'ml_models/mean_steps_xgboost_model.joblib',\n",
    "    \"Linear Regression on Fixation Probability\": 'ml_models/prob_fixation_linear_regression_pipeline.joblib',\n",
    "    \"XGBOOST on Fixation Probability\": 'ml_models/prob_fixation_xgboost_model.joblib',\n",
    "}\n",
    "\n",
    "TIME_LR_MODEL = \"Linear Regression on Fixation Time\"\n",
    "TIME_XGBOOST_MODEL = \"XGBOOST on Fixation Time\"\n",
    "PROB_LR_MODEL = \"Linear Regression on Fixation Probability\"\n",
    "PROB_XGBOOST_MODEL = \"XGBOOST on Fixation Probability\"\n",
    "\n",
    "\n",
    "model_name = TIME_LR_MODEL\n",
    "secondary_model_name = PROB_LR_MODEL\n",
    "\n",
    "# 1. Configuration\n",
    "params = {\n",
    "    \"initial_population\": graph_zoo, # Start with your random zoo\n",
    "    \"model\": joblib.load(models[model_name]),                     # Your trained Linear Regression\n",
    "    \"secondary_model\": joblib.load(models[secondary_model_name]),\n",
    "    \"generations\": GENERATIONS,               # How long to run\n",
    "    \"pop_size\": INITIAL_GRAPH_POPULATION,                  # Keep top 10 elite graphs\n",
    "    \"n_children\": NUMBER_OF_CHILDREN,                # Generate 30 new mutatesd graphs per graph in the population\n",
    "    \"objective\": \"minimize\",         # We want SLOW fixation\n",
    "    \"rng\": rng\n",
    "}\n",
    "# 2. Run\n",
    "final_pop, history = run_evolutionary_search(**params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # 3. Analyze Results\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Plot Learning Curve\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(history['best_fitness'], label=\"Best Fitness (Slowest)\")\n",
    "# plt.plot(history['avg_fitness'], label=\"Avg Fitness\", linestyle=\"--\")\n",
    "# plt.xlabel(\"Generation\")\n",
    "# plt.ylabel(\"Predicted Fixation Time\")\n",
    "# plt.title(f\"Evolution of Respiratory Topologies - Model {model_name}\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # 4. View the Champion\n",
    "# champion = final_pop[0]\n",
    "# print(f\"Champion Graph Name: {champion.name}\")\n",
    "# print(f\"Predicted Fixation Time: {history['best_fitness'][-1]:.2f}\")\n",
    "\n",
    "# # Visualize the champion (assuming you have a plot method)\n",
    "# # nx.draw(champion.graph, with_labels=True)\n",
    "\n",
    "\n",
    "# output_dir = Path(\"tmp_winning_graphs\")\n",
    "# output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# for graph in final_pop:\n",
    "#     graph.category = CATEGORY\n",
    "\n",
    "# joblib.dump(final_pop, output_dir / f\"{run_name}_zoo.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Analyze Results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the main figure and axis\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# --- PRIMARY AXIS (ax1) ---\n",
    "color_best = '#1f77b4'  # Standard Matplotlib blue\n",
    "color_avg = '#45b6fe'   # Lighter blue for average\n",
    "\n",
    "line1 = ax1.plot(history['best_fitness'], label=f\"Best: {model_name}\", color=color_best, linewidth=2)\n",
    "line2 = ax1.plot(history['avg_fitness'], label=f\"Avg: {model_name}\", color=color_avg, linestyle=\"--\", linewidth=2)\n",
    "\n",
    "ax1.set_xlabel(\"Generation\", fontweight='bold')\n",
    "\n",
    "# Smart labeling for primary axis\n",
    "if \"Probability\" in model_name:\n",
    "    ax1.set_ylabel(\"Fixation Probability\", color=color_best, fontweight='bold')\n",
    "    ax1.set_ylim(-0.05, 1.05) # Fix bounds for probability\n",
    "else:\n",
    "    ax1.set_ylabel(\"Fixation Time (Steps)\", color=color_best, fontweight='bold')\n",
    "\n",
    "ax1.tick_params(axis='y', labelcolor=color_best)\n",
    "ax1.grid(True, linestyle=':', alpha=0.7)\n",
    "\n",
    "# Combine lines for a unified legend later\n",
    "lines = line1 + line2\n",
    "\n",
    "# --- SECONDARY AXIS (ax2) ---\n",
    "if history['avg_fitness_secondary']:\n",
    "    ax2 = ax1.twinx()  # Instantiate a second axes that shares the same x-axis\n",
    "    color_sec = '#d62728'  # Standard Matplotlib red\n",
    "    \n",
    "    line3 = ax2.plot(history['avg_fitness_secondary'], label=f\"Avg Sec: {secondary_model_name}\", \n",
    "                     color=color_sec, linestyle=\"-.\", linewidth=2)\n",
    "    \n",
    "    # Smart labeling for secondary axis\n",
    "    if \"Probability\" in secondary_model_name:\n",
    "        ax2.set_ylabel(\"Fixation Probability\", color=color_sec, fontweight='bold')\n",
    "        ax2.set_ylim(-0.05, 1.05)\n",
    "    else:\n",
    "        ax2.set_ylabel(\"Fixation Time (Steps)\", color=color_sec, fontweight='bold')\n",
    "        \n",
    "    ax2.tick_params(axis='y', labelcolor=color_sec)\n",
    "    \n",
    "    # Append to our lines list for the unified legend\n",
    "    lines += line3\n",
    "\n",
    "# --- FINAL FORMATTING ---\n",
    "# Extract labels from the combined lines\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=True, ncol=3)\n",
    "\n",
    "plt.title(f\"Evolution of Respiratory Topologies\\nOptimizing: {model_name}\", fontsize=14, pad=15)\n",
    "fig.tight_layout() # Ensures the legend and labels don't get cut off\n",
    "plt.show()\n",
    "\n",
    "# 4. View the Champion\n",
    "champion = final_pop[0]\n",
    "# print(f\"Champion Graph Name: {champion.name}\")\n",
    "print(f\"Predicted Primary Fitness: {history['best_fitness'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for graph in graph_zoo:\n",
    "#     graph.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph in final_pop:\n",
    "    graph.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
