{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Moran Process on Different Graphs -New Database Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Set the style for nicer plots\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Import analysis utilities\n",
    "from analysis_utils import setup_analysis_environment, load_all_data\n",
    "\n",
    "# Setup environment and load data\n",
    "setup_analysis_environment()\n",
    "data = load_all_data()\n",
    "\n",
    "# Extract data for use in notebook\n",
    "df_graphs = data['graphs']\n",
    "df_experiments = data['random_test']  # or change to 'all_experiments' for all data\n",
    "\n",
    "# Try to import EXPERIMENTS_CSV from main.py\n",
    "try:\n",
    "    from main import EXPERIMENTS_CSV\n",
    "    print(f\"✓ Imported EXPERIMENTS_CSV: {EXPERIMENTS_CSV}\")\n",
    "except ImportError:\n",
    "    EXPERIMENTS_CSV = 'respiratory_runs.csv'\n",
    "    print(f\"✗ Could not import from main.py, using fallback: {EXPERIMENTS_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Colums of df_experiments: \\n\", df_experiments.columns)\n",
    "print(\"Colums of df_graphs: \\n\", df_graphs.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graphs['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(\n",
    "    df_experiments, \n",
    "    df_graphs, \n",
    "    on='wl_hash', \n",
    "    how='left', \n",
    "    suffixes=('', '_db') # If columns name clash (like 'n_nodes'), the DB one gets '_db'\n",
    ")\n",
    "df = df.filter(regex='^(?!.*_db)')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "This code block is here only for some of it's design, will delete later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get list of unique graphs\n",
    "# unique_graphs = df['wl_hash'].unique()\n",
    "\n",
    "# for graph_hash in unique_graphs:\n",
    "#     # Get subset for this graph\n",
    "#     graph_subset = df[df['wl_hash'] == graph_hash]\n",
    "#     unique_r_values = graph_subset['r'].unique()\n",
    "#     n_nodes = graph_subset['n_nodes'].iloc[0]\n",
    "#     graph_name = graph_subset['graph_name'].iloc[0]\n",
    "#     for r in unique_r_values:\n",
    "#         # Filter data for this specific graph and r value\n",
    "#         subset = graph_subset[graph_subset['r'] == r]\n",
    "#         fixation_subset = subset[subset['fixation'] == True]\n",
    "        \n",
    "#         # Calculate statistics\n",
    "#         p_fix = subset['fixation'].mean()\n",
    "#         n_runs = len(subset)\n",
    "#         n_success = len(fixation_subset)\n",
    "        \n",
    "#         # Create figure\n",
    "#         fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "#         # Main title with statistics\n",
    "#         fig.suptitle(f\"Graph: {graph_name} | n_nodes: {n_nodes} | r: {r} | Runs: {n_runs} | P(fix): {p_fix:.3f} ({n_success}/{n_runs})\", \n",
    "#                     fontsize=14, fontweight='bold')\n",
    "        \n",
    "#         # Plot 1: All runs histogram\n",
    "#         if not subset.empty:\n",
    "#             bins = max(10, min(50, int(subset['steps'].max() - subset['steps'].min()) // 5))\n",
    "            \n",
    "#             # Separate data by fixation status\n",
    "#             fixation_steps = subset[subset['fixation'] == True]['steps']\n",
    "#             extinction_steps = subset[subset['fixation'] == False]['steps']\n",
    "            \n",
    "#             # Plot stacked histogram\n",
    "#             axes[0].hist([extinction_steps, fixation_steps], \n",
    "#                         bins=bins, \n",
    "#                         label=['Extinction', 'Fixation'],\n",
    "#                         color=['gray', 'green'],\n",
    "#                         alpha=0.7,\n",
    "#                         stacked=True)\n",
    "#         median_steps = subset['steps'].median()\n",
    "#         axes[0].axvline(median_steps, color='red', linestyle='--', alpha=0.8, label=f'Median: {median_steps:.0f}')\n",
    "#         axes[0].set_title(f\"Distribution of Steps (All Runs)\")\n",
    "#         axes[0].set_xlabel(\"Steps\")\n",
    "#         axes[0].set_ylabel(\"Frequency\")\n",
    "#         axes[0].legend()\n",
    "#         axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "#         # Plot 2: Fixation-only histogram\n",
    "#         if not fixation_subset.empty:\n",
    "#             bins = max(5, min(30, len(fixation_subset) // 3))\n",
    "#             axes[1].hist(fixation_subset['steps'], \n",
    "#                         bins=bins, \n",
    "#                         color='green', \n",
    "#                         alpha=0.7, \n",
    "#                         edgecolor='black', \n",
    "#                         linewidth=0.5)\n",
    "            \n",
    "#             median_steps_fixed = fixation_subset['steps'].median()\n",
    "#             axes[1].axvline(median_steps_fixed, color='red', linestyle='--', alpha=0.8, \n",
    "#                            label=f'Median: {median_steps_fixed:.0f}')\n",
    "#             axes[1].set_title(f\"Distribution of Steps (Fixation Events Only)\")\n",
    "#             axes[1].set_xlabel(\"Steps to Fixation\")\n",
    "#             axes[1].set_ylabel(\"Frequency\")\n",
    "#             axes[1].legend()\n",
    "#             axes[1].grid(True, alpha=0.3)\n",
    "#         else:\n",
    "#             axes[1].text(0.5, 0.5, \"No Fixation Events Observed\", \n",
    "#                         horizontalalignment='center', verticalalignment='center', \n",
    "#                         fontsize=14, transform=axes[1].transAxes)\n",
    "#             axes[1].set_title(\"Distribution of Steps (Fixation Events Only)\")\n",
    "#             axes[1].set_xlabel(\"Steps to Fixation\")\n",
    "#             axes[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Histogram plots of the steps to fixation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of unique graphs\n",
    "unique_graphs = df['wl_hash'].unique()\n",
    "\n",
    "for graph_hash in unique_graphs:\n",
    "    # 1. Create a subset for this graph ONCE (Optimization)\n",
    "    graph_subset = df[df['wl_hash'] == graph_hash]\n",
    "    \n",
    "    # 2. Extract Metadata (FIX: Use .iloc[0] to get the single value, not a Series)\n",
    "    # We use 'n_nodes' if it came from the DB merge, or 'n_nodes' if from the experiment data\n",
    "    n_nodes = graph_subset['n_nodes'].iloc[0] if 'n_nodes' in graph_subset.columns else graph_subset['n_nodes'].iloc[0]\n",
    "    graph_name = graph_subset['graph_name'].iloc[0]\n",
    "    \n",
    "    # Get the r values present for this specific graph\n",
    "    unique_r_values = sorted(graph_subset['r'].unique())\n",
    "\n",
    "    for r in unique_r_values:\n",
    "        # 3. Filter data for this specific r\n",
    "        subset = graph_subset[graph_subset['r'] == r]\n",
    "        \n",
    "        # 4. Filter for only successful fixations\n",
    "        fixation_subset = subset[subset['fixation'] == True]\n",
    "        \n",
    "        # 5. Calculate Statistics\n",
    "        p_fix = subset['fixation'].mean()\n",
    "        n_runs = len(subset)\n",
    "        n_success = len(fixation_subset)\n",
    "        \n",
    "        # --- PLOTTING ---\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Main Title\n",
    "        fig.suptitle(f\"Graph: {graph_name} | N: {n_nodes} | r: {r} | Runs: {n_runs} | P(fix): {p_fix:.3f} ({n_success}/{n_runs})\", \n",
    "                     fontsize=14, fontweight='bold', y=1.05)\n",
    "        \n",
    "        # Plot 1: Stacked Histogram (Fixation vs Extinction)\n",
    "        sns.histplot(data=subset, x='steps', hue='fixation', multiple=\"stack\", \n",
    "                     ax=axes[0], palette={True: 'green', False: 'gray'}, bins=30)\n",
    "        median_all = subset['steps'].median()\n",
    "        axes[0].axvline(median_all, color='red', linestyle='--', alpha=0.8, label=f'Median: {median_all:.0f}')\n",
    "        axes[0].set_title(f\"All Runs (Fixation + Extinction)\\nMedian: {median_all:.0f} steps\")\n",
    "        axes[0].set_xlabel(\"Steps\")\n",
    "        axes[0].set_ylabel(\"Count\")\n",
    "        \n",
    "        # Plot 2: Fixation Only\n",
    "        if not fixation_subset.empty:\n",
    "            sns.histplot(data=fixation_subset, x='steps', ax=axes[1], color='green', kde=True, bins=20)\n",
    "            median_fix = fixation_subset['steps'].median()\n",
    "            axes[1].axvline(median_fix, color='red', linestyle='--', alpha=0.8, label=f'Median: {median_fix:.0f}')\n",
    "            axes[1].set_title(f\"Successful Fixations Only\\nMedian: {median_fix:.0f} steps\")\n",
    "            axes[1].set_xlabel(\"Steps to Fixation\")\n",
    "            axes[1].set_ylabel(\"Count\")\n",
    "        else:\n",
    "            # Handle case with 0 fixations (cleaner UI)\n",
    "            axes[1].text(0.5, 0.5, \"No Fixation Events\", \n",
    "                         horizontalalignment='center', verticalalignment='center', fontsize=12)\n",
    "            axes[1].set_title(\"Successful Fixations Only\")\n",
    "            axes[1].axis('off') # Hides the empty axes\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Probabilities and median steps tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# TABLE 1: Median Steps (Only Successful Fixations)\n",
    "# ---------------------------------------------------------\n",
    "fixation_df = df[df['fixation'] == True]\n",
    "\n",
    "# 1. Pivot using Hash (Logic: Keep distinct graphs separate)\n",
    "table_med_fixation = fixation_df.pivot_table(\n",
    "    index=['graph_name', 'n_nodes', 'wl_hash'], \n",
    "    columns='r', \n",
    "    values='steps', \n",
    "    aggfunc='median'\n",
    ")\n",
    "\n",
    "# 2. Sort by Row Average\n",
    "table_med_fixation = table_med_fixation.assign(row_mean=table_med_fixation.mean(axis=1)) \\\n",
    "                                       .sort_values('row_mean') \\\n",
    "                                       .drop(columns='row_mean')\n",
    "\n",
    "# 3. Drop Hash from Display (Presentation: Hide the ugly ID)\n",
    "# This keeps the rows separate but removes the hash column from the view\n",
    "table_med_fixation.index = table_med_fixation.index.droplevel('wl_hash')\n",
    "\n",
    "print(\"--- Table 1: Median Steps (Only Successful Fixations) [Sorted] ---\")\n",
    "display(table_med_fixation)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# TABLE 2: Median Steps (All Runs)\n",
    "# ---------------------------------------------------------\n",
    "table_med_steps_absorption = df.pivot_table(\n",
    "    index=['graph_name', 'n_nodes', 'wl_hash'], \n",
    "    columns='r', \n",
    "    values='steps', \n",
    "    aggfunc='median'\n",
    ")\n",
    "\n",
    "# Sort and Clean\n",
    "table_med_steps_absorption = table_med_steps_absorption.assign(row_mean=table_med_steps_absorption.mean(axis=1)) \\\n",
    "                      .sort_values('row_mean') \\\n",
    "                      .drop(columns='row_mean')\n",
    "\n",
    "# Drop Hash from Display\n",
    "table_med_steps_absorption.index = table_med_steps_absorption.index.droplevel('wl_hash')\n",
    "\n",
    "print(\"\\n--- Table 2: Median Steps (All Runs) [Sorted] ---\")\n",
    "display(table_med_steps_absorption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------------\n",
    "# TABLE 3: Fixation Probability (P_fix)\n",
    "# ---------------------------------------------------------\n",
    "table_prob = df.pivot_table(\n",
    "    index=['graph_name', 'n_nodes', 'wl_hash'], \n",
    "    columns='r', \n",
    "    values='fixation', \n",
    "    aggfunc='mean'  # Mean of boolean = Probability\n",
    ")\n",
    "\n",
    "# Sort by Row Average (Descending: Highest probability at the top)\n",
    "table_prob = table_prob.assign(row_mean=table_prob.mean(axis=1)) \\\n",
    "                       .sort_values('row_mean', ascending=False) \\\n",
    "                       .drop(columns='row_mean')\n",
    "table_prob.index = table_prob.index.droplevel('wl_hash')\n",
    "print(\"--- Table 3: Fixation Probability (P_fix) [Sorted by High -> Low] ---\")\n",
    "display(table_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Aggregation Logic\n",
    "# FIX: Group by 'wl_hash' to ensure distinct graphs are calculated separately\n",
    "# even if they share the same name (e.g., multiple \"Random\" graphs).\n",
    "\n",
    "# Metric A: Fixation Probability (Using all data)\n",
    "prob_df = df.groupby(['graph_name', 'wl_hash', 'r'])['fixation'].mean().reset_index(name='prob_fixation')\n",
    "\n",
    "# Metric B: Median Steps (Using only SUCCESSFUL fixations)\n",
    "success_only_df = df[df['fixation'] == True]\n",
    "time_df = success_only_df.groupby(['graph_name', 'wl_hash', 'r'])['steps'].median().reset_index(name='median_steps')\n",
    "\n",
    "# Merge metrics into one plotting table\n",
    "# FIX: Merge on 'wl_hash' to ensure we match the right probability to the right time\n",
    "plot_data = pd.merge(prob_df, time_df, on=['graph_name', 'wl_hash', 'r'])\n",
    "\n",
    "# 3. Create Scatter Plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(\n",
    "    data=plot_data,\n",
    "    x='median_steps',\n",
    "    y='prob_fixation',\n",
    "    hue='graph_name',  # Color by name (groups similar types visually)\n",
    "    style='r',         # Shape by r\n",
    "    s=150,             # Make points larger\n",
    "    palette='deep',\n",
    "    alpha=0.9\n",
    ")\n",
    "\n",
    "# 4. Styling\n",
    "plt.title('Trade-off: Fixation Probability vs Time', fontsize=15)\n",
    "plt.xlabel('Median Steps to Fixation (Condition: Success)', fontsize=12)\n",
    "plt.ylabel('Probability of Fixation', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Move legend outside to keep plot clean\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Probability for an Active Step\n",
    "Here let's see if indeed the higher the multiplication of $N_{mut} \\times N_{wt}$ there is a higher chance for an active step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from population_graph import PopulationGraph\n",
    "# from process_run import ProcessRun\n",
    "\n",
    "# N = 100\n",
    "# r=1\n",
    "# sim = ProcessRun(PopulationGraph.complete_graph(N=N), selection_coefficient=r)\n",
    "# sim.initialize_random_mutant(n_mutants=N//2)\n",
    "# result = sim.run(track_history=True)\n",
    "            \n",
    "# history = result['history']\n",
    "# n_mutants = history[:-1]\n",
    "# n_wt = N - n_mutants\n",
    "# interaction_product = n_mutants * n_wt\n",
    "\n",
    "# is_active = (history[1:] != history[:-1]).astype(int)\n",
    "\n",
    "# interaction_df = pd.DataFrame({'interaction_product': interaction_product,\n",
    "#                                'is_active': is_active})\n",
    "\n",
    "# stats = interaction_df.groupby('interaction_product')['is_active'].mean().reset_index()\n",
    "# stats.columns = ['N_mutants x N_non_mutants', 'P(change)']\n",
    "\n",
    "# plt.figure(figsize=(6,8))\n",
    "# sns.regplot(data=stats, x=stats.columns[0], y=stats.columns[1])\n",
    "# plt.title(f'Correlation: Group Product vs Activity (N={N}, r={r})')\n",
    "# plt.ylabel('Probability of State Change P(t+1 ≠ t)')\n",
    "# plt.xlabel('Interaction Product (N_mut × N_wt)')\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
