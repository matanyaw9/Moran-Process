{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Analyse the Results of Running Moran Process Experiment on Different Graphs\n",
    "This is the newest version of this analysis file, where I can merge the csv of different jobs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd /home/labs/pilpel/matanyaw/moran-process \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "from analysis.analysis_utils import plot_hybrid_density, aggregate_results_no_load, GRAPH_PROPERTY_DESCRIPTION, COLOR_DICT\n",
    "# change this if on a different computer!\n",
    "from population_graph import GRAPH_PROPS\n",
    "# Set aesthetic parameters for \"publication-quality\" plots\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\", font_scale=1.2)\n",
    "plt.rcParams['figure.figsize'] = (12, 7)\n",
    "plt.rcParams['lines.linewidth'] = 2.5\n",
    "\n",
    "batch_name = 'batch_' + 'Test_batch_name_01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ROOT = Path(os.getcwd()) \n",
    "\n",
    "# Now define your paths relative to ROOT\n",
    "data_dir = ROOT / \"simulation_data\"\n",
    "batch_dir = data_dir / batch_name\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "output_file = os.path.join(batch_dir, f\"temp_full_results.csv\")\n",
    "tmp_results_path = os.path.join(batch_dir, \"tmp\", \"results\")\n",
    "all_files = glob.glob(os.path.join(tmp_results_path, \"result_job_*.csv\"))\n",
    "print(f\"Found {len(all_files)} files in temp results directory: {tmp_results_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_path = aggregate_results_no_load(batch_dir=batch_dir, delete_temp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(results_df_path)\n",
    "print(\"columns: \", results_df.columns)\n",
    "print(\"shape: \", results_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column where steps are NaN if fixation failed\n",
    "# This allows .agg() to ignore those values automatically for median/std\n",
    "results_df['steps_success'] = results_df['steps'].where(results_df['fixation'] == True)\n",
    "\n",
    "analysis_df = results_df.groupby(['wl_hash', 'r', 'graph_name']).agg(\n",
    "    prob_fixation=('fixation', 'mean'),\n",
    "    median_steps=('steps_success', 'median'),\n",
    "    mean_steps=('steps_success', 'mean'),\n",
    "    std_steps=('steps_success', 'std'),\n",
    "    q25_steps=('steps_success', lambda x: x.quantile(0.25)),\n",
    "    q75_steps=('steps_success', lambda x: x.quantile(0.75)),\n",
    "    iqr_steps=('steps_success', lambda x: x.quantile(0.75) - x.quantile(0.25)),\n",
    "    n_grouped=('fixation', 'size')\n",
    ").reset_index()\n",
    "\n",
    "print(\"Shape before merging: \", analysis_df.shape)\n",
    "# df_graphs = load_experiment_data('graph_database.csv')       # Graph database\n",
    "df_graphs = pd.read_csv(os.path.join(batch_dir, 'graph_props.csv'))\n",
    "\n",
    "# Merge with graph metadata\n",
    "analysis_df = pd.merge(\n",
    "    analysis_df, \n",
    "    df_graphs, \n",
    "    on=['wl_hash', 'graph_name'], \n",
    "    how='left', \n",
    "    suffixes=('', '_db')\n",
    ")\n",
    "# Sorting\n",
    "analysis_df['z_order'] = (analysis_df['category'] != 'Random').astype(int)\n",
    "analysis_df = analysis_df.sort_values('z_order').drop(columns='z_order')\n",
    "analysis_df.to_csv(os.path.join(batch_dir, 'graph_statistics.csv'), index=False)\n",
    "\n",
    "\n",
    "print(\"Shape after merging: \", analysis_df.shape)\n",
    "# Display sample\n",
    "analysis_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(analysis_df['mean_steps'], bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Mean Steps')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Mean Steps')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge results_df and analysis_df on wl_hash and graph_name, excluding Random category\n",
    "merged_df = pd.merge(\n",
    "    results_df,\n",
    "    df_graphs[df_graphs['category'] != 'Random'],\n",
    "    on=['wl_hash', 'graph_name'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Filter out Random category graphs\n",
    "print(f\"Merged dataframe shape: {merged_df.shape}\")\n",
    "merged_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GRAPH_PROPERTY_DESCRIPTION['avg_degree_centrality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlaid histograms of steps_success by category\n",
    "categories = [\"Mammalian\", \"Fish\", \"Avian\", \"Accelerator\", \"Decelerator\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Define common bins based on all data\n",
    "animal_results = merged_df.loc[merged_df['category'].isin(categories), 'steps_success'].dropna()\n",
    "# bins = 50  # or use: bins = np.linspace(all_data.min(), all_data.max(), 51)\n",
    "bins = np.linspace(animal_results.min(), animal_results.max(), 51)\n",
    "\n",
    "for category in categories:\n",
    "    data = merged_df.loc[merged_df['category'] == category, 'steps_success'].dropna()\n",
    "    plt.hist(data, bins=bins, alpha=0.4, edgecolor='black', label=category, color=COLOR_DICT[category])\n",
    "\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Steps to Fixation by Category')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hybrid_density(analysis_df, 'std_steps', 'mean_steps', with_violin=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hybrid_density(analysis_df, 'max_betweenness_centrality', 'mean_steps', with_violin=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hybrid_density(analysis_df, 'max_degree_centrality', 'mean_steps', with_violin=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hybrid_density(analysis_df, 'max_degree', 'prob_fixation', with_violin=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_plot = analysis_df[analysis_df['r'] == 1.1]\n",
    "\n",
    "# NEW_GRAPH_PROPS = ['avg_degree', 'max_degree']\n",
    "print(GRAPH_PROPS)\n",
    "# plot_hybrid_density(df_to_plot, 'mean_steps', 'std_steps', with_violin=False)\n",
    "plot_hybrid_density(analysis_df, 'prob_fixation', 'mean_steps', with_violin=False)\n",
    "plot_hybrid_density(analysis_df, 'mean_steps', 'prob_fixation', with_violin=False)\n",
    "\n",
    "\n",
    "# --- EXAMPLES OF USAGE ---\n",
    "for prop in GRAPH_PROPS:\n",
    "    # plot_property_effect(df_to_plot, prop, 'median_steps')\n",
    "    plot_hybrid_density(df_to_plot, prop, 'mean_steps', density_threshold=50, with_violin=True)\n",
    "    # plot_hybrid_density(df_to_plot, prop, 'prob_fixation', density_threshold=50, with_violin=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hybrid_density(df_to_plot, 'degree_std', 'mean_steps', density_threshold=50, with_violin=True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.hexbin(df_to_plot['degree_std'], df_to_plot['mean_steps'], gridsize=20, cmap='YlOrRd', mincnt=1)\n",
    "plt.xlabel('degree_std')\n",
    "plt.ylabel('mean_steps')\n",
    "plt.colorbar(label='count')\n",
    "plt.title('Hexbin plot: degree_std vs mean_steps')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Moran Process",
   "language": "python",
   "name": "moran-process"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
