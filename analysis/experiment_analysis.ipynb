{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Analyse the Results of Running Moran Process Experiment on Different Graphs\n",
    "This is the newest version of this analysis file, where I can merge the csv of different jobs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "from analysis_utils import aggregate_results, plot_property_effect, plot_hybrid_density\n",
    "# change this if on a different computer!\n",
    "%cd /home/labs/pilpel/matanyaw/moran-process \n",
    "from population_graph import GRAPH_PROPS\n",
    "# Set aesthetic parameters for \"publication-quality\" plots\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\", font_scale=1.2)\n",
    "plt.rcParams['figure.figsize'] = (12, 7)\n",
    "plt.rcParams['lines.linewidth'] = 2.5\n",
    "\n",
    "batch_name = 'batch_' + 'small_test_01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ROOT = Path(os.getcwd()) \n",
    "\n",
    "# Now define your paths relative to ROOT\n",
    "data_dir = ROOT / \"simulation_data\"\n",
    "batch_dir = data_dir / batch_name\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "\n",
    "\n",
    "output_file = os.path.join(batch_dir, f\"temp_full_results.csv\")\n",
    "tmp_results_path = os.path.join(batch_dir, \"tmp\", \"results\")\n",
    "all_files = glob.glob(os.path.join(tmp_results_path, \"result_job_*.csv\"))\n",
    "print(f\"Found {len(all_files)} files in temp results directory: {tmp_results_path}.\")\n",
    "shape_counts = {}\n",
    "\n",
    "for i, fname in enumerate(all_files):\n",
    "    with open(fname, 'r', encoding='utf-8') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        rows = list(reader)\n",
    "        n_rows = len(rows)\n",
    "        n_cols = len(rows[0]) if rows else 0\n",
    "        shape = (n_rows, n_cols)\n",
    "        shape_counts[shape] = shape_counts.get(shape, 0) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Shape counts of CSV files:\")\n",
    "total_rows = 0\n",
    "for shape, count in sorted(shape_counts.items()):\n",
    "    print(f\"  Shape {shape}: {count} files\")\n",
    "    total_rows += (shape[0]-1) * count\n",
    "\n",
    "# Calculate expected shape of aggregated CSV\n",
    "print(f\"Expected aggregated CSV shape: ({total_rows} rows)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = aggregate_results(batch_dir=batch_dir, delete_temp=False)\n",
    "print(\"Results Dataframe Shape : \", results_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"columns: \", results_df.columns)\n",
    "print(\"shape: \", results_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(results_df['fixation'] == True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column where steps are NaN if fixation failed\n",
    "# This allows .agg() to ignore those values automatically for median/std\n",
    "results_df['steps_success'] = results_df['steps'].where(results_df['fixation'] == True)\n",
    "\n",
    "analysis_df = results_df.groupby(['wl_hash', 'r', 'graph_name']).agg(\n",
    "    prob_fixation=('fixation', 'mean'),\n",
    "    median_steps=('steps_success', 'median'),\n",
    "    mean_steps=('steps_success', 'mean'),\n",
    "    std_steps=('steps_success', 'std'),\n",
    "    q25_steps=('steps_success', lambda x: x.quantile(0.25)),\n",
    "    q75_steps=('steps_success', lambda x: x.quantile(0.75)),\n",
    "    iqr_steps=('steps_success', lambda x: x.quantile(0.75) - x.quantile(0.25)),\n",
    "    n_grouped=('fixation', 'size')\n",
    ").reset_index()\n",
    "\n",
    "print(\"Shape before merging: \", analysis_df.shape)\n",
    "# df_graphs = load_experiment_data('graph_database.csv')       # Graph database\n",
    "df_graphs = pd.read_csv(os.path.join(batch_dir, 'graph_props.csv'))\n",
    "\n",
    "# Merge with graph metadata\n",
    "analysis_df = pd.merge(\n",
    "    analysis_df, \n",
    "    df_graphs, \n",
    "    on=['wl_hash', 'graph_name'], \n",
    "    how='left', \n",
    "    suffixes=('', '_db')\n",
    ")\n",
    "# Sorting\n",
    "analysis_df['z_order'] = (analysis_df['category'] != 'Random').astype(int)\n",
    "analysis_df = analysis_df.sort_values('z_order').drop(columns='z_order')\n",
    "analysis_df.to_csv(os.path.join(batch_dir, 'graph_statistics.csv'), index=False)\n",
    "\n",
    "\n",
    "print(\"Shape after merging: \", analysis_df.shape)\n",
    "# Display sample\n",
    "analysis_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(batch_dir, 'graph_props.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(GRAPH_PROPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(analysis_df['mean_steps'], bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Mean Steps')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Mean Steps')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_plot = analysis_df[analysis_df['r'] == 1.1]\n",
    "\n",
    "NEW_GRAPH_PROPS = ['avg_degree', 'max_degree']\n",
    "print(GRAPH_PROPS)\n",
    "# plot_hybrid_density(df_to_plot, 'mean_steps', 'std_steps', with_violin=False)\n",
    "plot_hybrid_density(analysis_df, 'mean_steps', 'prob_fixation', with_violin=False)\n",
    "\n",
    "# --- EXAMPLES OF USAGE ---\n",
    "for prop in GRAPH_PROPS:\n",
    "    # plot_property_effect(df_to_plot, prop, 'median_steps')\n",
    "    plot_hybrid_density(df_to_plot, prop, 'mean_steps', density_threshold=50, with_violin=True)\n",
    "    # plot_hybrid_density(df_to_plot, prop, 'prob_fixation', density_threshold=50, with_violin=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hybrid_density(df_to_plot, 'degree_std', 'mean_steps', density_threshold=50, with_violin=True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.hexbin(df_to_plot['degree_std'], df_to_plot['mean_steps'], gridsize=20, cmap='YlOrRd', mincnt=1)\n",
    "plt.xlabel('degree_std')\n",
    "plt.ylabel('mean_steps')\n",
    "plt.colorbar(label='count')\n",
    "plt.title('Hexbin plot: degree_std vs mean_steps')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
